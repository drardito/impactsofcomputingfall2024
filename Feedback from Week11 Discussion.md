## Feedback from Week 10 Discussion

![boy at microphone](https://images.unsplash.com/photo-1453738773917-9c3eff1db985?q=80&w=1770&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D)

I have had the pleasure of reading through your discussion from Week 10, where you used the evidence from notifications, etc., to speculate on who your computing systems understood you to be. Here is some feedback about your work in that discussion.

1. ***Engagement/Interaction/Substance***. So much of what you discussed had to with imbalances of power and the impact exerted on us. Here are some highlights:

   

   ***Global Impacts***

   @michelleb While reading the article Algorithmic Colonisation of Africa , the quote that stood out to me was “Data is necessarily always about something and never about an abstract entity. The collection, analysis, and manipulation of data potentially entails monitoring, tracking, and surveilling people”( Abeba Birhane).

   @cole.pattershon It seems to me that the algorithms these companies use may not have been intended to pray on their users or their addiction to social media but, now that they must know about it, seems incredibly morally wrong to allow to continue

   @orlandoa1 The article also draws attention to the growing dependence of multinational tech companies on African data, which is primarily taken without proper payment or oversight by African communities and governments.

   @pisapiat These entities harvest data as if it were a commodity without considering the well being of Africans and neglect privacy concerns altogether. 

   @timponeg We are always being watched. Data is constantly being collected on everyone and everything. But the actuality of it all and how companies use this data is not completely understood. The imbalance of knowledge and power is what makes the issue subtle especially when corporations have a stronger legal and financial foothold than individuals who are affected by their practices.

   

2. ***Visualizations.*** As you now know, I like to use computational tools to *analyze* these types of discussions. I think in a course of the Impacts of Computing, it makes sense (and for possibly interesting discussion) to use these types of computational tools. For this week (and throughout the course), I used/will use [Voyant Tools](https://voyant-tools.org/), which is a powerful tool designed to visualize various features of text. Here are some highlights of this analysis.

   1. *Features of your writing.*  By looking at these features of your writing, it is possible to learn some high level characteristics of your work. ***Volume of writing*** is a measurement of the quantity of your collective writing. For this week, you collectively used about 4500 words, which represents a big decrease from the previous Mattermost discussion (about 5700 words). This week, many of you wrote quite extensively and the other many of you wrote very briefly. I believe this bimodal distribution accounts for this decrease in volume. Additionally, about 1100 of the terms you used were unique, which is what it is. ***Vocabulary density*** is a measure of how rich or varied the vocabulary is in a given text or corpus. A vocabulary density of 0.242 means that, on average, about 24% of the words in the corpus are unique. This is slightly higher than last time, and this makes sense since many of you were talking about the same kinds of global impacts of data privacy. 

      ![summary of features of writing for this week](https://github.com/drardito/impactsofcomputingfall2024/blob/main/Images/Impacts%20FA24%20Week10%20Features.png?raw=true)

   2. *Word Frequencies*. This word cloud represents the relative frequencies of the words you used in your posts. As mentioned above, the most frequently used (largest) terms reflect on the common set of notifications/evidence you cited in your post: *algorithms*, *data*, *privacy*, and *companies* (no surprise, there). As usual, we see the relatively high frequency of the word *pm*, which is taken from the date/time stamp in Mattermost. 

      ![wordcloud](https://github.com/drardito/impactsofcomputingfall2024/blob/main/Images/Impacts%20FA24%20Week10%20Wordcloud.png?raw=true)

   3. *Relationships Between Words.* As usual, I performed a ***collocation analysis***, in which we can look at the relationships between works used in your Mattermost posts. In this visualization, thicker grey lines indicate a higher number of connections between terms. I invite you to explore a [live version of this analysis](https://voyant-tools.org/?corpus=efddc612fc7a7279ae7dd31c50d3dbe8&query=algorithms&query=companies&query=think&query=tech&query=power&query=way&query=data&query=use&query=africa&query=information&query=pm&query=november&query=agree&query=wilmerroldan&query=week%27s&query=reading&context=7&view=CollocatesGraph), which will allow you to explore these connections in interesting ways. Note the range of connected terms here, which is reflective of the global focus of this week's texts. And note the callout to @emilyramon who is frequently connected to other terms. Go, Wilmer and Matthew!  Please do play with the live version. I think you will be surprised by the connections you see there.

      ![word link chart](https://github.com/drardito/impactsofcomputingfall2024/blob/main/Images/Impacts%20FA24%20Week10%20Collocations.png?raw=true)

4. Topic Modeling. For the first time this semester, I used Voyant-Tools to do what is called *topic modeling*, which it defines this way: *The Topics tool is designed to help you understand what topics (term clusters) exist and how they are distributed. To simplify, words in each document are randomly assigned to a specified number of topics (you can determine the number of topics). The algorithm then goes through a number of iterations (50) and tries to refine the model of which terms are best suited to which topics (based on co-occurrence in the documents). It's important to understand that this algorithm starts by randomly assigning words to topics and so every time topic modelling is run you are likely to get different results. Each topic technically contains every word in the corpus, but only the top 10 words are displayed. The order of the words is important and the first words likely contribute much more to the topic than the latter words.*

   ![diagram of a topic model](https://github.com/drardito/impactsofcomputingfall2024/blob/main/Images/Impacts%20FA24%20Week10%20Topics.png?raw=true)

There are some components of this analysis which seem very coherent with the others, and some not so much. I am very eager to hear your responses to this type of analysis.

Please share your thoughts about any/all of this in the Week 10 discussion on Mattermost.
